{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7812b49e",
   "metadata": {},
   "source": [
    "# Task 3: Use Amazon Bedrock for Question Answering\n",
    "\n",
    "In this notebook, you learn how to use the Bedrock Nova Lite model to provide information responses to queries by sending the request with the full relevant context to the model and expecting the response back, addressing the challenge of having the model return factual answers for questions without needing to prepare and index documents beforehand.\n",
    "\n",
    "This notebook simulates what **Retrieval-Augmented Generation (RAG)** would do, but not actually using RAG. This approach works with short documents or single-ton applications; it might not scale to enterprise-level question answering where large enterprise documents cannot all be fit into the prompt sent to the model.\n",
    "\n",
    "**Question Answering (QA)** is an important task that involves extracting answers to factual queries posed in natural language. Typically, a QA system processes a query against a knowledge base containing structured or unstructured data and generates a response with accurate information. Ensuring high accuracy is key to developing a useful, reliable, and trustworthy question answering system, especially for enterprise use cases."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8004df1",
   "metadata": {},
   "source": [
    "\n",
    "## Scenario\n",
    "\n",
    "You try modeling a situation at AnyCompany where you ask a question answering model to provide information about changing tires for a specific vehicle model they manufacture. You first query the model using a \"zero shot\" approach to see if it can provide relevant answers based just on its training data.\n",
    "\n",
    "However, you realize the model seems to be \"hallucinating\" more generic answers, as evidenced when you try a fake vehicle model and get similar responses. This implies the need to augment the model's training with Example Company's actual vehicle manuals to give specifics on tires for each model.\n",
    "\n",
    "In this lab, you simulate such a \"Retrieval Augmented Generation\" (RAG) approach without external data. You provide a detailed manual excerpt explaining how to change the tires on the AnyCompany Model Z vehicle. You test if the model can now give a customized, accurate answer leveraging this in-context example content."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6491bf3b",
   "metadata": {},
   "source": [
    "## Task 3.1: Environment setup\n",
    "\n",
    "In this task, you set up your environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad7dbe9a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#ignore warnings and create a service client by name using the default session.\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "\n",
    "import boto3\n",
    "import botocore\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "module_path = \"..\"\n",
    "sys.path.append(os.path.abspath(module_path))\n",
    "bedrock_client = boto3.client('bedrock-runtime',region_name=os.environ.get(\"AWS_DEFAULT_REGION\", None))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87f42fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Nova Lite Adapter:\n",
    "\n",
    "This code block contains helper functions for using Nova Lite.\n",
    "\"\"\"\n",
    "\n",
    "import json\n",
    "import time\n",
    "from botocore.exceptions import ClientError\n",
    "\n",
    "def format_for_nova_lite(prompt_text):\n",
    "    \"\"\"Format the prompt for Nova Lite's expected message structure.\"\"\"\n",
    "    return {\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [{\"text\": prompt_text}]\n",
    "            }\n",
    "        ],\n",
    "        \"inferenceConfig\": {\n",
    "            \"maxTokens\": 2048,\n",
    "            \"temperature\": 0,\n",
    "            \"topP\": 0.9\n",
    "        }\n",
    "    }\n",
    "\n",
    "def parse_nova_lite_response(response_body):\n",
    "    \"\"\"Parse the response from Nova Lite.\"\"\"\n",
    "    if 'output' in response_body and 'message' in response_body['output']:\n",
    "        message = response_body['output']['message']\n",
    "        if 'content' in message and isinstance(message['content'], list):\n",
    "            # Extract text from each content item\n",
    "            texts = []\n",
    "            for content_item in message['content']:\n",
    "                if isinstance(content_item, dict) and 'text' in content_item:\n",
    "                    texts.append(content_item['text'])\n",
    "            return ' '.join(texts)\n",
    "    \n",
    "    # Fallback if the response format is different\n",
    "    return str(response_body)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f842ca3",
   "metadata": {},
   "source": [
    "## Task 3.2: Q&A with the knowledge of the model\n",
    "In this section we try to use a model provided by Bedrock service to answer questions based on the knowledge it gained during the training phase."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6c75356",
   "metadata": {},
   "source": [
    "In this task, you use the invoke_model() method of the Amazon Bedrock client. The mandatory parameters required to use this method are modelId, which represents the Amazon Bedrock model ARN, and body, which is the prompt for your task.\n",
    "\n",
    "The body prompt changes depending on the foundation model provider you select. You walk through this in detail below.\n",
    "\n",
    "```json\n",
    "{\n",
    "   modelId= model_id,\n",
    "   contentType= \"application/json\",\n",
    "   accept= \"application/json\",\n",
    "   body=body\n",
    "}\n",
    "\n",
    "```\n",
    "\n",
    "You try to use models provided by the Bedrock service to answer questions based on the knowledge gained during the training phase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e9c471",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt_data = \"\"\"You are an helpful automotive assistant. Answer questions in a concise way. When answering questions about car maintenance or repairs, provide a detailed, numbered list of steps. Assume all cars, including the AnyCompany AC8, have a spare tire. If you are unsure about the\n",
    "answer say 'I am unsure'\n",
    "\n",
    "Question: How can I fix a flat tire on my AnyCompany AC8?\n",
    "Answer:\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32bdfd16",
   "metadata": {},
   "source": [
    "<i aria-hidden=\"true\" class=\"fas fa-sticky-note\" style=\"color:#563377\"></i> **Note:** While running the code in upcoming tasks, you might observe *ThrottlingException* messages and retry attempts. Your code includes robust error handling that will automatically retry failed requests with exponential backoff. This is normal behavior when working with service quotas and demonstrates how production-ready applications should handle API limitations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bfcf189",
   "metadata": {},
   "source": [
    "## Task 3.3: Invoke the model by passing the JSON body to generate the response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3190577b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import time\n",
    "from botocore.exceptions import ClientError\n",
    "# Model configuration\n",
    "modelId = \"amazon.nova-lite-v1:0\"\n",
    "accept = \"application/json\"\n",
    "contentType = \"application/json\"\n",
    "\n",
    "# Retry configuration\n",
    "max_retries = 5\n",
    "retry_delay = 10  # seconds\n",
    "\n",
    "def invoke_model_with_retry(bedrock_client, modelId, prompt_text, contentType, accept, max_retries, retry_delay):\n",
    "    \"\"\"Invoke the model with retry logic.\"\"\"\n",
    "    # Format the prompt for Nova Lite\n",
    "    body = format_for_nova_lite(prompt_text)\n",
    "    \n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            response = bedrock_client.invoke_model(\n",
    "                modelId=modelId,\n",
    "                body=json.dumps(body),\n",
    "                contentType=contentType,\n",
    "                accept=accept\n",
    "            )\n",
    "            \n",
    "            response_body = json.loads(response.get('body').read())\n",
    "            return parse_nova_lite_response(response_body)\n",
    "\n",
    "        except ClientError as error:\n",
    "            if error.response['Error']['Code'] == 'AccessDeniedException':\n",
    "                print(f\"\\x1b[41m{error.response['Error']['Message']}\\\\n\\\n",
    "                \\nTo troubleshoot this issue please refer to the following resources:\\\\n\\\n",
    "                \\nhttps://docs.aws.amazon.com/IAM/latest/UserGuide/troubleshoot_access-denied.html\\\\n\\\n",
    "                \\nhttps://docs.aws.amazon.com/bedrock/latest/userguide/security-iam.html\\x1b[0m\\n\")      \n",
    "                raise\n",
    "\n",
    "            elif error.response['Error']['Code'] in ['ThrottlingException', 'ServiceUnavailableException']:\n",
    "                if attempt < max_retries - 1:\n",
    "                    print(f\"Service capacity reached. Retrying in {retry_delay} seconds...\")\n",
    "                    time.sleep(retry_delay)\n",
    "                    retry_delay *= 2  # Exponential backoff\n",
    "                else:\n",
    "                    print(\"Max retries reached. Unable to invoke the model.\")\n",
    "                    raise\n",
    "\n",
    "            else:\n",
    "                print(f\"An error occurred: {error}\")\n",
    "                raise\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"An unexpected error occurred: {e}\")\n",
    "            raise\n",
    "\n",
    "# Main execution\n",
    "try:\n",
    "    result = invoke_model_with_retry(bedrock_client, modelId, prompt_data, contentType, accept, max_retries, retry_delay)\n",
    "    print(result)\n",
    "except Exception as e:\n",
    "    print(f\"Failed to invoke the model after retries: {e}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89fb9445",
   "metadata": {},
   "source": [
    "\n",
    "The model gives you an answer outlining the process of changing the car's flat tire, but the same explanation could be valid for any car. Unfortunately, this is not the right answer for an AnyCompany AC8, which does not have a spare tire. This occurs because the model has been trained on data containing instructions about changing tires on cars.\n",
    "\n",
    "Another example of this issue can be seen by trying to ask the same question for a completely fake car brand and model, say an Amazon Tirana."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48aeeea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import time\n",
    "from botocore.exceptions import ClientError\n",
    "\n",
    "# Usage\n",
    "prompt_data = \"\"\"How can I fix a flat tire on my Amazon Tirana?\n",
    "Answer: Here are the steps to fix a flat tire:\n",
    "\"\"\"\n",
    "\n",
    "def invoke_model_with_retry(prompt_data, max_retries=5, initial_delay=10):\n",
    "    modelId = \"amazon.nova-lite-v1:0\"\n",
    "    accept = \"application/json\"\n",
    "    contentType = \"application/json\"\n",
    "    \n",
    "    # Format the prompt for Nova Lite\n",
    "    body = json.dumps(format_for_nova_lite(prompt_data))\n",
    "    \n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            response = bedrock_client.invoke_model(\n",
    "                body=body, \n",
    "                modelId=modelId, \n",
    "                accept=accept, \n",
    "                contentType=contentType\n",
    "            )\n",
    "            response_body = json.loads(response.get(\"body\").read())\n",
    "            return parse_nova_lite_response(response_body)\n",
    "\n",
    "        except ClientError as error:\n",
    "            error_code = error.response['Error']['Code']\n",
    "            \n",
    "            if error_code == 'AccessDeniedException':\n",
    "                print(f\"\\x1b[41m{error.response['Error']['Message']}\\\\n\\\n",
    "                \\nTo troubleshoot this issue please refer to the following resources:\\\\n\\\n",
    "                \\nhttps://docs.aws.amazon.com/IAM/latest/UserGuide/troubleshoot_access-denied.html\\\\n\\\n",
    "                \\nhttps://docs.aws.amazon.com/bedrock/latest/userguide/security-iam.html\\x1b[0m\\n\")\n",
    "                raise\n",
    "                \n",
    "            elif error_code in ['ThrottlingException', 'ServiceUnavailableException', 'ModelStreamLimitExceededException']:\n",
    "                if attempt < max_retries - 1:\n",
    "                    delay = initial_delay * (2 ** attempt)  # Exponential backoff\n",
    "                    print(f\"Service capacity reached. Retrying in {delay} seconds...\")\n",
    "                    print(f\"Error: {error}\")\n",
    "                    time.sleep(delay)\n",
    "                    continue\n",
    "                else:\n",
    "                    print(f\"Max retries ({max_retries}) reached. Last error: {error}\")\n",
    "                    raise\n",
    "            else:\n",
    "                print(f\"Unhandled error occurred: {error}\")\n",
    "                raise\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Unexpected error: {e}\")\n",
    "            if attempt < max_retries - 1:\n",
    "                delay = initial_delay * (2 ** attempt)\n",
    "                print(f\"Retrying in {delay} seconds...\")\n",
    "                time.sleep(delay)\n",
    "                continue\n",
    "            else:\n",
    "                raise\n",
    "\n",
    "try:\n",
    "    # Invoke model with retry logic\n",
    "    result = invoke_model_with_retry(prompt_data)\n",
    "    # Print the raw result\n",
    "    if result:\n",
    "        print(result.strip())\n",
    "    else:\n",
    "        print(\"No response generated from the model.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Failed to get response after all retries: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "259499df",
   "metadata": {},
   "source": [
    "Given the prompt question, the model is unable to provide a realistic answer.\n",
    "\n",
    "To fix this issue and have the model provide answers based on the specific instructions valid for your car model, you can augment the model's knowledge on-the-fly by providing an additional knowledge base as part of the prompt.\n",
    "\n",
    "Let's see how you can use this to improve your application.\n",
    "\n",
    "Assume the following is an excerpt from the manual of the AnyCompany AC8 (in reality, it is not the real manual, but treat it as such). This document is also conveniently short enough to fit entirely in the Nova Lite context window.\n",
    "\n",
    "```plain\n",
    "Tires and Tire Pressure:\n",
    "\n",
    "Tires are made of black rubber and are mounted on the wheels of your vehicle. They provide the necessary grip for driving, cornering, and braking. Two important factors to consider are tire pressure and tire wear, as they can affect the performance and handling of your car.\n",
    "\n",
    "Where to Find Recommended Tire Pressure:\n",
    "\n",
    "You can find the recommended tire pressure specifications on the inflation label located on the driver's side B-pillar of your vehicle. Alternatively, you can refer to your vehicle's manual for this information. The recommended tire pressure may vary depending on the speed and the number of occupants or maximum load in the vehicle.\n",
    "\n",
    "Reinflating the Tires:\n",
    "\n",
    "When checking tire pressure, it is important to do so when the tires are cold. This means allowing the vehicle to sit for at least three hours to ensure the tires are at the same temperature as the ambient temperature.\n",
    "\n",
    "To reinflate the tires:\n",
    "\n",
    "    Check the recommended tire pressure for your vehicle.\n",
    "    Follow the instructions provided on the air pump and inflate the tire(s) to the correct pressure.\n",
    "    In the center display of your vehicle, open the \"Car status\" app.\n",
    "    Navigate to the \"Tire pressure\" tab.\n",
    "    Press the \"Calibrate pressure\" option and confirm the action.\n",
    "    Drive the car for a few minutes at a speed above 30 km/h to calibrate the tire pressure.\n",
    "\n",
    "Note: In some cases, it may be necessary to drive for more than 15 minutes to clear any warning symbols or messages related to tire pressure. If the warnings persist, allow the tires to cool down and repeat the above steps.\n",
    "\n",
    "Flat Tire:\n",
    "\n",
    "If you encounter a flat tire while driving, you can temporarily seal the puncture and reinflate the tire using a tire mobility kit. This kit is typically stored under the lining of the luggage area in your vehicle.\n",
    "\n",
    "Instructions for Using the Tire Mobility Kit:\n",
    "\n",
    "    Open the tailgate or trunk of your vehicle.\n",
    "    Lift up the lining of the luggage area to access the tire mobility kit.\n",
    "    Follow the instructions provided with the tire mobility kit to seal the puncture in the tire.\n",
    "    After using the kit, make sure to securely put it back in its original location.\n",
    "    Contact Rivesla or an appropriate service for assistance with disposing of and replacing the used sealant bottle.\n",
    "\n",
    "Please note that the tire mobility kit is a temporary solution and is designed to allow you to drive for a maximum of 10 minutes or 8 km (whichever comes first) at a maximum speed of 80 km/h. It is advisable to replace the punctured tire or have it repaired by a professional as soon as possible.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2817e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "context = \"\"\"Tires and tire pressure:\n",
    "\n",
    "Tires are made of black rubber and are mounted on the wheels of your vehicle. They provide the necessary grip for driving, cornering, and braking. Two important factors to consider are tire pressure and tire wear, as they can affect the performance and handling of your car.\n",
    "\n",
    "Where to find recommended tire pressure:\n",
    "\n",
    "You can find the recommended tire pressure specifications on the inflation label located on the driver's side B-pillar of your vehicle. Alternatively, you can refer to your vehicle's manual for this information. The recommended tire pressure may vary depending on the speed and the number of occupants or maximum load in the vehicle.\n",
    "\n",
    "Reinflating the tires:\n",
    "\n",
    "When checking tire pressure, it is important to do so when the tires are cold. This means allowing the vehicle to sit for at least three hours to ensure the tires are at the same temperature as the ambient temperature.\n",
    "\n",
    "To reinflate the tires:\n",
    "\n",
    "    Check the recommended tire pressure for your vehicle.\n",
    "    Follow the instructions provided on the air pump and inflate the tire(s) to the correct pressure.\n",
    "    In the center display of your vehicle, open the \"Car status\" app.\n",
    "    Navigate to the \"Tire pressure\" tab.\n",
    "    Press the \"Calibrate pressure\" option and confirm the action.\n",
    "    Drive the car for a few minutes at a speed above 30 km/h to calibrate the tire pressure.\n",
    "\n",
    "Note: In some cases, it may be necessary to drive for more than 15 minutes to clear any warning symbols or messages related to tire pressure. If the warnings persist, allow the tires to cool down and repeat the above steps.\n",
    "\n",
    "Flat Tire:\n",
    "\n",
    "If you encounter a flat tire while driving, you can temporarily seal the puncture and reinflate the tire using a tire mobility kit. This kit is typically stored under the lining of the luggage area in your vehicle.\n",
    "\n",
    "Instructions for using the tire mobility kit:\n",
    "\n",
    "    Open the tailgate or trunk of your vehicle.\n",
    "    Lift up the lining of the luggage area to access the tire mobility kit.\n",
    "    Follow the instructions provided with the tire mobility kit to seal the puncture in the tire.\n",
    "    After using the kit, make sure to securely put it back in its original location.\n",
    "    Contact AnyCompany or an appropriate service for assistance with disposing of and replacing the used sealant bottle.\n",
    "\n",
    "Please note that the tire mobility kit is a temporary solution and is designed to allow you to drive for a maximum of 10 minutes or 8 km (whichever comes first) at a maximum speed of 80 km/h. It is advisable to replace the punctured tire or have it repaired by a professional as soon as possible.\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "190ff32c",
   "metadata": {},
   "source": [
    "##### Now, pass the whole excerpt to the model together with the question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "475daa7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"How can I fix a flat tire on my AnyCompany AC8?\"\n",
    "prompt_data = f\"\"\"Answer the question based only on the information provided between ## and give step by step guide in 5 steps with conclusion.\n",
    "#\n",
    "{context}\n",
    "#\n",
    "\n",
    "Question: {question}\n",
    "Answer:\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "093deebf",
   "metadata": {},
   "source": [
    "### Task 3.4: Invoke the model via boto3 to generate the response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "703ce8ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import time\n",
    "from botocore.exceptions import ClientError\n",
    "\n",
    "def invoke_nova_lite_with_retry(prompt_data, max_retries=5, initial_delay=10):\n",
    "    # Format the prompt for Nova Lite\n",
    "    body = json.dumps(format_for_nova_lite(prompt_data))\n",
    "    modelId = \"amazon.nova-lite-v1:0\"  \n",
    "    accept = \"application/json\"\n",
    "    contentType = \"application/json\"\n",
    "\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            response = bedrock_client.invoke_model(\n",
    "                body=body, \n",
    "                modelId=modelId, \n",
    "                accept=accept, \n",
    "                contentType=contentType\n",
    "            )\n",
    "            response_body = json.loads(response.get(\"body\").read())\n",
    "            return parse_nova_lite_response(response_body)\n",
    "\n",
    "        except ClientError as error:\n",
    "            error_code = error.response['Error']['Code']\n",
    "            \n",
    "            if error_code == 'AccessDeniedException':\n",
    "                print(f\"\\x1b[41m{error.response['Error']['Message']}\\\\n\\\n",
    "                \\nTo troubleshoot this issue please refer to the following resources:\\\\n\\\n",
    "                \\nhttps://docs.aws.amazon.com/IAM/latest/UserGuide/troubleshoot_access-denied.html\\\\n\\\n",
    "                \\nhttps://docs.aws.amazon.com/bedrock/latest/userguide/security-iam.html\\x1b[0m\\n\")\n",
    "                raise\n",
    "            \n",
    "            elif error_code in ['ThrottlingException', 'ServiceUnavailableException', 'ModelStreamLimitExceededException']:\n",
    "                if attempt < max_retries - 1:\n",
    "                    delay = initial_delay * (2 ** attempt)  # Exponential backoff\n",
    "                    print(f\"Service capacity reached. Retrying in {delay} seconds...\")\n",
    "                    print(f\"Error: {error}\")\n",
    "                    time.sleep(delay)\n",
    "                    continue\n",
    "                else:\n",
    "                    print(f\"Max retries ({max_retries}) reached. Last error: {error}\")\n",
    "                    raise\n",
    "            else:\n",
    "                print(f\"Unhandled error occurred: {error}\")\n",
    "                raise\n",
    "                \n",
    "        except Exception as e:\n",
    "            if attempt < max_retries - 1:\n",
    "                delay = initial_delay * (2 ** attempt)\n",
    "                print(f\"Unexpected error: {e}\")\n",
    "                print(f\"Retrying in {delay} seconds...\")\n",
    "                time.sleep(delay)\n",
    "                continue\n",
    "            else:\n",
    "                print(f\"Failed after {max_retries} attempts. Last error: {e}\")\n",
    "                raise\n",
    "\n",
    "# Usage\n",
    "try:\n",
    "    answer = invoke_nova_lite_with_retry(prompt_data)\n",
    "    print(answer.strip())\n",
    "except Exception as e:\n",
    "    print(f\"Final error: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06ce75f8",
   "metadata": {},
   "source": [
    "Since the model takes a while to understand the context and generate a relevant answer for you, this might lead to a poor user experience as they have to wait for a response for some seconds.\n",
    "\n",
    "Bedrock also supports streaming capability where the service generates output as the model generates tokens. Here is an example of how you can implement that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3811cfe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display_markdown,Markdown,clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63bee1dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import time\n",
    "from botocore.exceptions import ClientError\n",
    "\n",
    "def invoke_nova_lite_stream_with_retry(prompt_data, max_retries=5, initial_delay=10):\n",
    "    body = json.dumps(format_for_nova_lite(prompt_data))\n",
    "    modelId = \"amazon.nova-lite-v1:0\"\n",
    "    accept = \"application/json\"\n",
    "    contentType = \"application/json\"\n",
    "    \n",
    "    print(f\"Using model: {modelId}\")\n",
    "\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            response = bedrock_client.invoke_model_with_response_stream(\n",
    "                body=body, \n",
    "                modelId=modelId, \n",
    "                accept=accept, \n",
    "                contentType=contentType\n",
    "            )\n",
    "            \n",
    "            stream = response.get('body')\n",
    "            output = []\n",
    "            i = 1\n",
    "            \n",
    "            if stream:\n",
    "                for event in stream:\n",
    "                    chunk = event.get('chunk')\n",
    "                    if chunk:\n",
    "                        chunk_obj = json.loads(chunk.get('bytes').decode())\n",
    "                        # Extract text from Nova Lite's response format\n",
    "                        if 'contentBlockDelta' in chunk_obj and 'delta' in chunk_obj['contentBlockDelta']:\n",
    "                            text = chunk_obj['contentBlockDelta']['delta'].get('text', '')\n",
    "                            clear_output(wait=True)\n",
    "                            output.append(text)\n",
    "                            display_markdown(Markdown(''.join(output)))\n",
    "                            i += 1\n",
    "                return ''.join(output)  # Return the complete output\n",
    "            else:\n",
    "                raise Exception(\"No stream data received\")\n",
    "\n",
    "        except ClientError as error:\n",
    "            error_code = error.response['Error']['Code']\n",
    "            \n",
    "            if error_code == 'AccessDeniedException':\n",
    "                print(f\"\\x1b[41m{error.response['Error']['Message']}\\\\n\\\n",
    "                \\nTo troubleshoot this issue please refer to the following resources:\\\\n\\\n",
    "                \\nhttps://docs.aws.amazon.com/IAM/latest/UserGuide/troubleshoot_access-denied.html\\\\n\\\n",
    "                \\nhttps://docs.aws.amazon.com/bedrock/latest/userguide/security-iam.html\\x1b[0m\\n\")\n",
    "                raise\n",
    "            \n",
    "            elif error_code in ['ThrottlingException', 'ServiceUnavailableException', 'ModelStreamLimitExceededException']:\n",
    "                if attempt < max_retries - 1:\n",
    "                    delay = initial_delay * (2 ** attempt)  # Exponential backoff\n",
    "                    print(f\"Service capacity reached. Retrying in {delay} seconds...\")\n",
    "                    print(f\"Error: {error}\")\n",
    "                    time.sleep(delay)\n",
    "                    continue\n",
    "                else:\n",
    "                    print(f\"Max retries ({max_retries}) reached. Last error: {error}\")\n",
    "                    raise\n",
    "            else:\n",
    "                print(f\"Unhandled error occurred: {error}\")\n",
    "                raise\n",
    "                \n",
    "        except Exception as e:\n",
    "            if attempt < max_retries - 1:\n",
    "                delay = initial_delay * (2 ** attempt)\n",
    "                print(f\"Unexpected error: {e}\")\n",
    "                print(f\"Retrying in {delay} seconds...\")\n",
    "                time.sleep(delay)\n",
    "                continue\n",
    "            else:\n",
    "                print(f\"Failed after {max_retries} attempts. Last error: {e}\")\n",
    "                raise\n",
    "\n",
    "# Usage\n",
    "try:\n",
    "    # You can adjust retry parameters here\n",
    "    result = invoke_nova_lite_stream_with_retry(\n",
    "        prompt_data,\n",
    "        max_retries=5,\n",
    "        initial_delay=10\n",
    "    )\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Final error: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b9b1019",
   "metadata": {},
   "source": [
    "The response provides summarized, step-by-step instructions on how to change the tires. \n",
    "\n",
    "You have now learned how you can leverage the Retrieval Augmented Generation (RAG) or the Augmentation process to generate a curated response tailored to the specific context and information provided."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64c3e2ed",
   "metadata": {},
   "source": [
    "### Try it yourself\n",
    "- Change the prompts to your specific usecase and evaluate the output of different models.\n",
    "- Play with the token length to understand the latency and responsiveness of the service.\n",
    "- Apply different prompt engineering principles to get better outputs.\n",
    "\n",
    "### Cleanup\n",
    "\n",
    "You have completed this notebook. To move to the next part of the lab, do the following:\n",
    "\n",
    "- Close this notebook file and continue with **Task 4**."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
